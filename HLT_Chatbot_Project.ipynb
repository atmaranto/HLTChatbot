{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HLT Chatbot Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HLT Chatbot Project\n",
        "*Written by Anthony Maranto for the project by Anthony Maranto (ATM170000) and Usaid Malik (UXM170001).*\n",
        "\n",
        "Simply run every cell in this notebook (Runtime -> Run all), scroll to the bottom, and wait for it to prompt you for your input. As long as you don't reset the runtime, data should be stored and retained in the database across sessions JUST SO LONG as you don't interrupt individual cells. This means that, if you want to restart the bot while retaining the same data, you should use \"Runtime\" -> \"Restart and run all\"; that will ensure that the CoreNLP environment is properly reloaded."
      ],
      "metadata": {
        "id": "1oE15VOlXJc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eFoG-KOLXG8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939d918f-db00-4f73-ef19-1d43e85296ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chatbot code\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4267k  100 4267k    0     0  2682k      0  0:00:01  0:00:01 --:--:-- 2680k\n",
            "Unzipping with supplied password\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists(\"bot.py\"):\n",
        "  print(\"Downloading chatbot code\")\n",
        "  !curl https://personal.utdallas.edu/~atm170000/ChatbotHLT.zip --insecure > ChatbotHLT.zip\n",
        "\n",
        "  password = b\"usaid_and_tonys_chatbot_project_for_hlt_passw0rd\"\n",
        "\n",
        "  print(\"Unzipping with supplied password\")\n",
        "  from zipfile import ZipFile\n",
        "  zf = ZipFile(\"ChatbotHLT.zip\")\n",
        "\n",
        "  zf.extractall(\".\", pwd=password)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "if not os.path.isfile(\"CoreNLP.zip\"):\n",
        "  print(\"Downloading Stanford CoreNLP\")\n",
        "  !curl -L https://nlp.stanford.edu/software/stanford-corenlp-latest.zip > CoreNLP.zip\n",
        "  print(\"Extracting Stanford CoreNLP\")\n",
        "  !unzip CoreNLP.zip\n",
        "\n",
        "  f = open(\"corenlp.pth\", \"w\")\n",
        "  jf_1 = glob.glob(\"stanford-corenlp-?.?.?/stanford-corenlp-?.?.?.jar\")[0]\n",
        "  jf_2 = glob.glob(\"stanford-corenlp-?.?.?/stanford-corenlp-?.?.?-models.jar\")[0]\n",
        "  f.write(jf_1 + \"\\n\" + jf_2)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "BA77VZl2X8zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de899c3-2824-4b56-9112-131cfaf4ac4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Stanford CoreNLP\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0   355    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  482M  100  482M    0     0  5399k      0  0:01:31  0:01:31 --:--:-- 5189k\n",
            "Extracting Stanford CoreNLP\n",
            "Archive:  CoreNLP.zip\n",
            "   creating: stanford-corenlp-4.5.0/\n",
            "  inflating: stanford-corenlp-4.5.0/pom-java-11.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/corenlp.sh  \n",
            "  inflating: stanford-corenlp-4.5.0/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/Makefile  \n",
            "  inflating: stanford-corenlp-4.5.0/input.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-core-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/jaxb-api-2.4.0-b180830.0359.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/stanford-corenlp-4.5.0-javadoc.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/joda-time.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/LIBRARY-LICENSES  \n",
            "  inflating: stanford-corenlp-4.5.0/protobuf-java-3.19.2.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/StanfordCoreNlpDemo.java  \n",
            "  inflating: stanford-corenlp-4.5.0/stanford-corenlp-4.5.0.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/README.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/build.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/input.txt.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/pom-java-17.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/jollyday.jar  \n",
            "   creating: stanford-corenlp-4.5.0/sutime/\n",
            "  inflating: stanford-corenlp-4.5.0/sutime/english.holidays.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/sutime/spanish.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/sutime/british.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/istack-commons-runtime-3.0.7.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/xom-1.3.7-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/stanford-corenlp-4.5.0-models.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/sample-project-pom.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/xom.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/javax.json.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/slf4j-api.jar  \n",
            "   creating: stanford-corenlp-4.5.0/tokensregex/\n",
            "  inflating: stanford-corenlp-4.5.0/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-4.5.0/pom.xml  \n",
            "  inflating: stanford-corenlp-4.5.0/input.txt.out  \n",
            "  inflating: stanford-corenlp-4.5.0/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/RESOURCE-LICENSES  \n",
            "  inflating: stanford-corenlp-4.5.0/javax.activation-api-1.2.0.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/jaxb-impl-2.4.0-b180830.0438.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-4.5.0/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-simple-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/istack-commons-runtime-3.0.7-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/LICENSE.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/javax.activation-api-1.2.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/stanford-corenlp-4.5.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-core-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/ShiftReduceDemo.java  \n",
            "   creating: stanford-corenlp-4.5.0/patterns/\n",
            " extracting: stanford-corenlp-4.5.0/patterns/places.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/patterns/goldnames.txt  \n",
            " extracting: stanford-corenlp-4.5.0/patterns/goldplaces.txt  \n",
            " extracting: stanford-corenlp-4.5.0/patterns/otherpeople.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/patterns/example.properties  \n",
            "  inflating: stanford-corenlp-4.5.0/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/patterns/names.txt  \n",
            "  inflating: stanford-corenlp-4.5.0/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-ddense-0.39.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/StanfordDependenciesManual.pdf  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-ddense-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/ejml-simple-0.39-sources.jar  \n",
            "  inflating: stanford-corenlp-4.5.0/joda-time-2.10.5-sources.jar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat corenlp.pth"
      ],
      "metadata": {
        "id": "8PUwvhdadtOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3fb289-43b4-41ab-be4c-474f6452bc12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stanford-corenlp-4.5.0/stanford-corenlp-4.5.0.jar\n",
            "stanford-corenlp-4.5.0/stanford-corenlp-4.5.0-models.jar"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To run on Colab, we need to alter corenlp.py slightly to get around used Colab ports\n",
        "\n",
        "#@markdown\n",
        "f = open(\"corenlp.py\", \"w\")\n",
        "f.write('''\n",
        "# A test script that runs the input through CoreNLP through NLTK\n",
        "\n",
        "import atexit, sys, os, code\n",
        "from nltk.parse.corenlp import CoreNLPServer, CoreNLPParser\n",
        "from nltk import word_tokenize\n",
        "\n",
        "print(\"Loading CoreNLP Server...\")\n",
        "\n",
        "config_file = \"corenlp.pth\"\n",
        "if not os.path.isfile(config_file):\n",
        "    warning_msg = f\"Warning: {config_file} does not exist. Hopefully, the required jarfiles for Stanford CoreNLP are in the path. \" + \\\n",
        "                  f\"Otherwise, please download them from https://stanfordnlp.github.io/CoreNLP/download.html and put the paths to \" + \\\n",
        "                  f\"stanford-corenlp-X.X.X.jar and stanford-corenlp-X.X.X-models.jar as the first two lines of corenlp.pth.\"\n",
        "    print(warning_msg, file=sys.stderr)\n",
        "    corenlp_server = None\n",
        "    corenlp_models = None\n",
        "else:\n",
        "    with open(config_file, \"r\") as f:\n",
        "        corenlp_server = f.readline().strip()\n",
        "        corenlp_models = f.readline().strip()\n",
        "\n",
        "corenlp_options = [\"-preload\", \"tokenize,ssplit,pos,lemma,parse,depparse,ner,openie\"]\n",
        "\n",
        "import random\n",
        "port = random.randint(9000, 30000)\n",
        "print(\"Using port\", port)\n",
        "\n",
        "corenlp_options.append(\"-port\")\n",
        "corenlp_options.append(str(port))\n",
        "\n",
        "server = CoreNLPServer(corenlp_server, corenlp_models, corenlp_options=corenlp_options, port=port)\n",
        "server.start() #(open(\"stdout.log\", \"wb\"), open(\"stderr.log\", \"wb\"))\n",
        "atexit.register(server.stop)\n",
        "\n",
        "parser = CoreNLPParser(server.url)\n",
        "\n",
        "# item = list(parser.parse(word_tokenize(\"The end of the world is upon us, and Mario Kart 3 won't help.\")))[0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if 'interact' in sys.argv:\n",
        "        code.interact(local=locals())\n",
        "    else:\n",
        "        print(\"Enter sentences to be parsed\")\n",
        "        while True:\n",
        "            for i, tree in enumerate(parser.parse(word_tokenize(input(\"> \")))):\n",
        "                print(f\"Tree {i+1}:\")\n",
        "                print(tree)\n",
        "''')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "eoyyR-srh0ZO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workaround the expectation that the server will start up within thirty seconds\n",
        "path = \"/usr/local/lib/python3.7/dist-packages/nltk/parse/corenlp.py\"\n",
        "data = open(path, \"r\").read()\n",
        "f = open(path, \"w\")\n",
        "data = data.replace(\"for i in range(30):\", \"for i in range(90):\\n            print('waiting...' + str(i + 1))\\n\")\n",
        "data = data.replace(\"def try_port(port=0):\\n\", \"def try_port(port=0):\\n    return port\\n\")\n",
        "stem = '''            raise CoreNLPServerError(\n",
        "                'Could not connect to the server.'\n",
        "            )'''\n",
        "data = data.replace(stem, '            if self.popen.poll() is not None: print(self.popen.poll(), self.popen.communicate()[1].decode(\"utf-8\"))\\n' + stem.replace(\"Could\", \"!!Could\"))\n",
        "f.write(data)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "JqLJCqIqmJ8z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nltk and download necessary extra submodules\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "IfbSszcSuJP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9388421e-b0ca-4531-c8b0-dd647a161703"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Please note: loading CoreNLP may take up to ninety seconds.\")\n",
        "from bot import *"
      ],
      "metadata": {
        "id": "d0Ei43pkfIQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5baae21-88c5-442c-88c7-e8e5484a63ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please note: loading CoreNLP may take up to ninety seconds.\n",
            "Loading CoreNLP Server...\n",
            "Using port 10057\n",
            "waiting...1\n",
            "waiting...2\n",
            "waiting...3\n",
            "waiting...4\n",
            "waiting...5\n",
            "waiting...6\n",
            "waiting...7\n",
            "waiting...8\n",
            "waiting...9\n",
            "waiting...10\n",
            "waiting...11\n",
            "waiting...12\n",
            "waiting...13\n",
            "waiting...14\n",
            "waiting...15\n",
            "waiting...16\n",
            "waiting...17\n",
            "waiting...18\n",
            "waiting...19\n",
            "waiting...20\n",
            "waiting...21\n",
            "waiting...22\n",
            "waiting...23\n",
            "waiting...24\n",
            "waiting...25\n",
            "waiting...26\n",
            "waiting...27\n",
            "waiting...28\n",
            "waiting...29\n",
            "waiting...30\n",
            "waiting...31\n",
            "waiting...32\n",
            "waiting...33\n",
            "waiting...34\n",
            "waiting...35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "ujkNI-wds54a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warning_message = \"\"\"\n",
        "Due to bugs with Google Colab (CoreNLP *REALLY* doesn't like being run here),\n",
        "if you stop this cell, it will cause the internal CoreNLP server to quit. To\n",
        "resolve this, if you would like to test this bot's data persistence, then\n",
        "please use \"Runtime\" -> \"Restart and run all\" to restart the bot. DO NOT just\n",
        "interrupt the execution or \"break\" a single cell, as that will likely cause a\n",
        "connection error. \n",
        "\"\"\"\n",
        "print(\"Starting bot process.\")\n",
        "print(warning_message.strip())\n",
        "\n",
        "bot = GameBot()\n",
        "try:\n",
        "  bot.loop()\n",
        "except requests.exceptions.ConnectionError:\n",
        "  print(\"ConnectionError! Did you forget to use \\\"Restart and run all\\\" when\")\n",
        "  print(\"restarting this bot? Just interrupting (or \\\"quit\\\"ting and rerunning the cell) won't work!\")"
      ],
      "metadata": {
        "id": "f2KYgXMEr5eE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f0ff29-81f0-42cb-c68d-19131bb6e1b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting bot process.\n",
            "Due to bugs with Google Colab (CoreNLP *REALLY* doesn't like being run here),\n",
            "if you stop this cell, it will cause the internal CoreNLP server to quit. To\n",
            "resolve this, if you would like to test this bot's data persistence, then\n",
            "please use \"Runtime\" -> \"Restart and run all\" to restart the bot. DO NOT just\n",
            "interrupt the execution or \"break\" a single cell, as that will likely cause a\n",
            "connection error.\n",
            "Welcome back Tony. Type \"logout\" to log out.\n",
            "Enter your prompt for GameBot. Type \"quit\" to quit.\n",
            "> tony\n",
            "Invalid input; please try again.\n",
            "Enter your prompt for GameBot. Type \"quit\" to quit.\n",
            "> What is Tony?\n",
            "1 responses matched your query:\n",
            "Tony is a human\n",
            "Enter your prompt for GameBot. Type \"quit\" to quit.\n",
            "> What is Usaid?\n",
            "I'm afraid that I don't know much about that.\n",
            "Enter your prompt for GameBot. Type \"quit\" to quit.\n",
            "> quit\n"
          ]
        }
      ]
    }
  ]
}